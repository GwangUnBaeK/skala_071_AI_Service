# nodes/market_node.py
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from state.graph_state import GraphState
from tools.market_tool import search_market_reports
from utils.logger import logger
from config.settings import settings

B2B_MARKET_TEMPLATES = [
    {
        "demand_name": "SME automation",
        "problem_statement": "ì¤‘ì†Œê¸°ì—…ì˜ íšŒê³„Â·ì¸ì‚¬Â·ê³ ê°ì§€ì› ì—…ë¬´ë¥¼ AIë¡œ ìë™í™”í•˜ì—¬ ë¹„ìš©ì„ ì ˆê°",
        "industries": ["Manufacturing", "Finance", "Retail"],
        "search_keywords": ["SME automation AI", "enterprise RPA AI", "workflow automation AI"],
        "tam_usd": 12_000_000_000,  # $12B
        "cagr": 0.28,  # 28% CAGR
        "target_companies": 150_000,
        "regions": ["Global", "North America", "Europe", "Asia-Pacific"],
    },
    {
        "demand_name": "Contact center automation",
        "problem_statement": "ê³ ê° ì‘ëŒ€ ì—…ë¬´ë¥¼ AI Agentì™€ ìŒì„±ì¸ì‹ìœ¼ë¡œ ìë™í™”",
        "industries": ["Telecom", "Banking", "Insurance"],
        "search_keywords": ["contact center AI", "call center AI", "voicebot AI customer support"],
        "tam_usd": 8_000_000_000,  # $8B
        "cagr": 0.32,  # 32% CAGR
        "target_companies": 80_000,
        "regions": ["Global", "North America", "Asia-Pacific"],
    },
    {
        "demand_name": "Developer productivity",
        "problem_statement": "AI ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ í™œìš©í•´ ê°œë°œì ìƒì‚°ì„±ì„ í–¥ìƒ",
        "industries": ["IT Services", "Software"],
        "search_keywords": ["developer productivity AI", "AI code assistant", "software engineering AI"],
        "tam_usd": 10_000_000_000,  # $10B
        "cagr": 0.35,  # 35% CAGR
        "target_companies": 200_000,
        "regions": ["Global"],
    },
    {
        "demand_name": "Privacy and sovereign AI",
        "problem_statement": "ë°ì´í„° ì£¼ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ ì˜¨í”„ë ˆë¯¸ìŠ¤ AI ì†”ë£¨ì…˜ ìˆ˜ìš” í™•ëŒ€",
        "industries": ["Public Sector", "Finance", "Healthcare"],
        "search_keywords": ["sovereign AI", "private LLM", "AI data governance"],
        "tam_usd": 6_000_000_000,  # $6B
        "cagr": 0.22,  # 22% CAGR
        "target_companies": 30_000,
        "regions": ["Europe", "Asia-Pacific", "Middle East"],
    },
    {
        "demand_name": "Manufacturing quality",
        "problem_statement": "ìƒì‚° ë¼ì¸ì˜ í’ˆì§ˆ ê²€ì‚¬ë¥¼ AI ë¹„ì „ìœ¼ë¡œ ìë™í™”",
        "industries": ["Manufacturing", "Automotive"],
        "search_keywords": ["AI visual inspection", "smart factory AI", "industrial AI"],
        "tam_usd": 7_000_000_000,  # $7B
        "cagr": 0.26,  # 26% CAGR
        "target_companies": 50_000,
        "regions": ["Asia-Pacific", "North America", "Europe"],
    },
    {
        "demand_name": "Health diagnostics",
        "problem_statement": "ì˜ë£Œì˜ìƒ ë° ì§„ë‹¨ AIë¡œ ì˜ì‚¬ ì˜ì‚¬ê²°ì •ì„ ì§€ì›",
        "industries": ["Healthcare"],
        "search_keywords": ["medical imaging AI", "diagnostics AI", "healthcare AI platform"],
        "tam_usd": 9_000_000_000,  # $9B
        "cagr": 0.30,  # 30% CAGR
        "target_companies": 40_000,
        "regions": ["Global", "North America", "Europe"],
    },
    {
        "demand_name": "Personalized learning",
        "problem_statement": "AI ê¸°ë°˜ í•™ìŠµì ë§ì¶¤í˜• êµìœ¡ ì½˜í…ì¸  ì œê³µ",
        "industries": ["Education Tech"],
        "search_keywords": ["personalized learning AI", "adaptive education AI", "edtech AI"],
        "tam_usd": 5_000_000_000,  # $5B
        "cagr": 0.27,  # 27% CAGR
        "target_companies": 100_000,
        "regions": ["Global", "North America", "Asia-Pacific"],
    },
]


def market_analysis_node(state: GraphState) -> GraphState:
    """
    Agent 3: ì‹œì¥ ë¶„ì„ (B2B ì¤‘ì‹¬)
    - B2B_MARKET_TEMPLATES ê¸°ë°˜ ì‹œì¥ ê¸°íšŒ í‰ê°€
    - Tavily APIë¡œ ì‹¤ì‹œê°„ ì‹œì¥ ë¦¬í¬íŠ¸ ê²€ìƒ‰
    - ì‹œì¥ ê·œëª¨(TAM), ì„±ì¥ë¥ (CAGR), íƒ€ê²Ÿ ê¸°ì—… ìˆ˜ í¬í•¨
    """
    logger.info("=" * 70)
    logger.info("ğŸ“ˆ Agent 3: ì‹œì¥ ë¶„ì„ ì‹œì‘ (B2B ì¤‘ì‹¬)")
    logger.info("=" * 70)

    keywords = state.get("keywords", []) or []
    keywords_lower = [str(k).lower() for k in keywords]
    error_log = state.get("error_log", [])
    results = []

    for domain in B2B_MARKET_TEMPLATES:
        demand = domain["demand_name"]
        search_terms = domain["search_keywords"]
        logger.info(f"\nğŸ” ì‹œì¥ ê²€ìƒ‰ â†’ {demand}")

        # Tavily ê²€ìƒ‰
        try:
            tavily_reports = search_market_reports.invoke({
                "queries": search_terms,
                "max_results": settings.LIMITS.get("market_max_per_query", 5)
            })
        except Exception as e:
            msg = f"Tavily ê²€ìƒ‰ ì‹¤íŒ¨ ({demand}): {e}"
            logger.error(msg)
            error_log.append(msg)
            tavily_reports = []

        # ê¸°íšŒ ì ìˆ˜ ê³„ì‚°
        base_score = 50.0
        base_score += min(len(tavily_reports) * 8.0, 40.0)  # ë¦¬í¬íŠ¸ ìˆ˜ ê¸°ë°˜

        # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤
        search_terms_text = " ".join(search_terms).lower()
        overlap = any(k in search_terms_text for k in keywords_lower)
        if overlap:
            base_score += 10.0

        final_score = round(min(base_score, 100.0), 1)

        # ìƒìœ„ 3ê°œ ë¦¬í¬íŠ¸ë§Œ ì¦ê±°ë¡œ ì €ì¥
        top_reports = tavily_reports[:3] if tavily_reports else []
        evidence_links = [
            {
                "title": r.get("title", ""),
                "url": r.get("url", ""),
                "source": r.get("source", ""),
                "published_date": r.get("published_date", "")
            }
            for r in top_reports
        ]

        # âœ… ê²°ê³¼ ìƒì„± (í…œí”Œë¦¿ì˜ ì‹œì¥ ë°ì´í„° í¬í•¨)
        result = {
            "market_id": f"market_{len(results):03d}",
            "demand_name": domain["demand_name"],
            "opportunity_score": final_score,
            "industries": domain["industries"],
            "problem_statement": domain["problem_statement"],
            
            # âœ… ì‹œì¥ ë°ì´í„° (í…œí”Œë¦¿ì—ì„œ ê°€ì ¸ì˜´)
            "tam_usd": domain["tam_usd"],
            "cagr": domain["cagr"],
            "target_companies": domain["target_companies"],
            "regions": domain["regions"],
            
            "evidence": {
                "reports": evidence_links,
                "search_terms": search_terms
            }
        }
        results.append(result)
        
        logger.info(f" â†’ {demand:30s} | ê¸°íšŒì ìˆ˜ {final_score:5.1f} | ë¦¬í¬íŠ¸ {len(evidence_links)} ê±´")

    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: x["opportunity_score"], reverse=True)

    logger.info("\nìƒìœ„ 3ê°œ B2B ì‹œì¥ ê¸°íšŒ:")
    for i, r in enumerate(results[:3], 1):
        logger.info(f" {i}. {r['demand_name']:30s} ({r['opportunity_score']}ì )")

    logger.info("\n" + "=" * 70)
    logger.info("âœ… Agent 3: ì‹œì¥ ë¶„ì„ ì™„ë£Œ")
    logger.info("=" * 70 + "\n")

    return {
        "market_trends": results,
        "messages": [{
            "role": "assistant",
            "content": f"ì‹œì¥ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ë„ë©”ì¸ í‰ê°€"
        }],
        "step_market": "completed",
        "error_log": error_log
    }