# nodes/tech_node.py
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from state.graph_state import GraphState
from collections import Counter
from utils.logger import logger

# -----------------------------
# íŠœë‹ ê°€ëŠ¥í•œ ê¸°ì¤€ê°’ (B2B ì œí’ˆí™” ì¤‘ì‹¬)
# -----------------------------
ELIGIBILITY_MIN_REPOS = 2        # ë ˆí¬ ìˆ˜ê°€ ì´ ê°’ ë¯¸ë§Œì´ê³ 
ELIGIBILITY_MIN_STARS = 200      # ì´ Starsë„ ì´ ê°’ ë¯¸ë§Œì´ë©´ â†’ ì œì™¸
PENALTY_MIN_REPOS = 3            # ë ˆí¬ ìˆ˜ê°€ ì´ ê°’ ë¯¸ë§Œì´ë©´ ê²½ë¯¸í•œ ê°ì 
PENALTY_MIN_STARS = 500          # ì´ Starsê°€ ì´ ê°’ ë¯¸ë§Œì´ë©´ ê²½ë¯¸í•œ ê°ì 

def calculate_maturity_score(paper_count: int, github_stars: int, num_repos: int) -> float:
    """
    B2B ì œí’ˆí™” ì¤‘ì‹¬ ì„±ìˆ™ë„ ê³„ì‚°:
    - ì œí’ˆí™” ë¹„ìœ¨(60%) + GitHub í™œë™(40%)
    - ì œí’ˆí™” ë¹„ìœ¨: ë ˆí¬ ìˆ˜ / (ë…¼ë¬¸ ìˆ˜/80) â†’ ìƒí•œ 1.0
    - GitHub í™œë™: ì´ Stars / 50,000 â†’ ìƒí•œ 1.0
    """
    # ì œí’ˆí™” ë¹„ìœ¨ (ë…¼ë¬¸ ëŒ€ë¹„ êµ¬í˜„ ë¹ˆë„)
    denom = max(paper_count / 80.0, 1.0)  # ë” ì—„ê²©í•œ ë¶„ëª¨
    product_ratio = min(num_repos / denom, 1.0)

    # GitHub í™œë™
    github_score = min(github_stars / 50000.0, 1.0)

    score = (0.6 * product_ratio + 0.4 * github_score) * 100.0
    return round(score, 1)

def tech_analysis_node(state: GraphState) -> GraphState:
    """
    Agent 2: ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ (ê°œì„ íŒ)
    - ë…¼ë¬¸ í‚¤ì›Œë“œ ë¹ˆë„ â†’ ìƒìœ„ í›„ë³´ ì¶”ì¶œ
    - GitHubì™€ ë§¤ì¹­í•˜ì—¬ 'ì œí’ˆí™” ì¤‘ì‹¬' ì„±ìˆ™ë„ ê³„ì‚°
    - ìµœì†Œ ë ˆí¬/ìŠ¤íƒ€ ê¸°ì¤€ìœ¼ë¡œ 'ì—°êµ¬ë§Œ ëœ¨ê±°ìš´' í‚¤ì›Œë“œ ì œì™¸/ê°ì 
    - ê·¼ê±°(evidence) í•„ë“œ ì¶”ê°€
    """
    logger.info("="*70)
    logger.info("ğŸ”¬ Agent 2: ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘ (B2B ì œí’ˆí™” ì¤‘ì‹¬)")
    logger.info("="*70)

    papers = state.get("papers", [])
    github_repos = state.get("github_repos", [])

    logger.info(f"\nì…ë ¥ ë°ì´í„°:")
    logger.info(f"   - ë…¼ë¬¸: {len(papers)}ê°œ")
    logger.info(f"   - GitHub: {len(github_repos)}ê°œ\n")

    # 1) ë…¼ë¬¸ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
    all_keywords = []
    for paper in papers:
        all_keywords.extend(paper.get("keywords", []))

    keyword_counts = Counter([k for k in all_keywords if k])  # ë¹ˆ ë¬¸ìì—´ ë°©ì§€
    top_keywords = keyword_counts.most_common(20)  # ê³¼ë„ í™•ì¥ ë°©ì§€

    logger.info(f"ìƒìœ„ 20ê°œ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ\n")

    # 2) í‚¤ì›Œë“œë³„ GitHub ë§¤ì¹­ ë° ì„±ìˆ™ë„ ê³„ì‚°
    tech_trends = []

    for keyword, count in top_keywords:
        kw_lower = keyword.lower()

        # ê´€ë ¨ GitHub ì €ì¥ì†Œ ì°¾ê¸°(ì´ë¦„/ì„¤ëª… ë§¤ì¹­)
        related_repos = [
            r for r in github_repos
            if kw_lower in (r.get("name","").lower())
            or kw_lower in (r.get("description","").lower())
            or any(kw_lower == (k or "").lower() for k in r.get("keywords", []))
        ]

        total_stars = sum(int(r.get("stars", 0)) for r in related_repos)
        num_repos = len(related_repos)

        # ìê²©ìš”ê±´(eligibility) ì²´í¬: ë ˆí¬Â·ìŠ¤íƒ€ ëª¨ë‘ ë„ˆë¬´ ì ìœ¼ë©´ ì œì™¸
        if num_repos < ELIGIBILITY_MIN_REPOS and total_stars < ELIGIBILITY_MIN_STARS:
            # ì—°êµ¬ë§Œ ëœ¨ê±°ìš´ í‚¤ì›Œë“œë¡œ ê°„ì£¼í•˜ì—¬ ìŠ¤í‚µ
            continue

        # ê¸°ë³¸ ì„±ìˆ™ë„ ì ìˆ˜
        maturity_score = calculate_maturity_score(
            paper_count=count,
            github_stars=total_stars,
            num_repos=num_repos
        )

        # ê²½ë¯¸í•œ íŒ¨ë„í‹°: ì–´ëŠ í•œìª½ë§Œ ë¶€ì¡±í•  ë•Œ
        penalty_factor = 1.0
        if num_repos < PENALTY_MIN_REPOS:
            penalty_factor *= 0.90
        if total_stars < PENALTY_MIN_STARS:
            penalty_factor *= 0.92

        maturity_score = round(maturity_score * penalty_factor, 1)

        # ëŒ€í‘œ í”„ë¡œì íŠ¸ 3ê°œ (stars desc)
        top_projects = sorted(
            related_repos,
            key=lambda x: int(x.get("stars", 0)),
            reverse=True
        )[:3]

        evidence_projects = [
            {
                "name": p.get("name", ""),
                "url": p.get("url", p.get("html_url", "")),
                "stars": int(p.get("stars", 0))
            }
            for p in top_projects
        ]

        tech_trends.append({
            "tech_id": f"tech_{len(tech_trends):03d}",
            "tech_name": keyword,
            "maturity_score": maturity_score,
            "paper_count": int(count),
            "github_stars_total": int(total_stars),
            "num_repos": int(num_repos),
            "related_projects": [p["name"] for p in evidence_projects],
            "evidence": {
                "maturity": {
                    "paper_count": int(count),
                    "repo_count": int(num_repos),
                    "stars_total": int(total_stars),
                    "penalty_applied": penalty_factor < 1.0
                },
                "projects": evidence_projects
            }
        })

        logger.info(
            f"   [{len(tech_trends):2d}] {keyword:30s} | "
            f"ì„±ìˆ™ë„: {maturity_score:5.1f} | "
            f"ë…¼ë¬¸: {count:4d} | "
            f"Repos: {num_repos:3d} | "
            f"Stars: {total_stars:7d}"
        )

    # 3) ì„±ìˆ™ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    tech_trends.sort(key=lambda x: x["maturity_score"], reverse=True)

    logger.info(f"\nìƒìœ„ 5ê°œ ê¸°ìˆ  (ì„±ìˆ™ë„ ê¸°ì¤€):")
    for i, tech in enumerate(tech_trends[:5], 1):
        logger.info(f"   {i}. {tech['tech_name']:30s} ({tech['maturity_score']}ì )")

    logger.info("\n" + "="*70)
    logger.info("âœ… Agent 2: ê¸°ìˆ  ë¶„ì„ ì™„ë£Œ")
    logger.info("="*70)
    logger.info(f"   ì´ {len(tech_trends)}ê°œ ê¸°ìˆ  íŠ¸ë Œë“œ ë°œêµ´ (ìê²©ìš”ê±´ í•„í„° ì ìš©)")
    logger.info("="*70 + "\n")

    return {
        "tech_trends": tech_trends,
        "messages": [{
            "role": "assistant",
            "content": f"ê¸°ìˆ  ë¶„ì„ ì™„ë£Œ: {len(tech_trends)}ê°œ íŠ¸ë Œë“œ ë°œêµ´"
        }],
        "step_tech": "completed"
    }
