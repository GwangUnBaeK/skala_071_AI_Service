# nodes/collector_node.py
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from state.graph_state import GraphState
from tools.arxiv_tool import search_arxiv_papers
from tools.github_tool import search_github_repos
from tools.trends_tool import search_google_trends
from utils.logger import logger
from config.settings import settings

def data_collector_node(state: GraphState) -> GraphState:
    """
    Agent 1: ë°ì´í„° ìˆ˜ì§‘
    arXiv ë…¼ë¬¸, GitHub ì €ì¥ì†Œ, Google Trends ë°ì´í„° ìˆ˜ì§‘
    """
    logger.info("="*70)
    logger.info("ğŸ“Š Agent 1: ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    logger.info("="*70)
    
    keywords = state.get("keywords", settings.ANALYSIS["keywords"])
    logger.info(f"\nê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}\n")
    
    error_log = state.get("error_log", [])
    
    # 1. arXiv ë…¼ë¬¸ ìˆ˜ì§‘
    papers = []
    try:
        logger.info("1ï¸âƒ£ arXiv ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘...")
        papers = search_arxiv_papers.invoke({
            "keywords": keywords,
            "max_results": settings.LIMITS["arxiv_max_per_keyword"]
        })
        logger.info(f"   âœ… {len(papers)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ\n")
    except Exception as e:
        error_msg = f"arXiv ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
        logger.error(f"   âŒ {error_msg}\n")
        error_log.append(error_msg)
    
    # 2. GitHub ì €ì¥ì†Œ ìˆ˜ì§‘
    github_repos = []
    try:
        logger.info("2ï¸âƒ£ GitHub ì €ì¥ì†Œ ê²€ìƒ‰ ì¤‘...")
        github_repos = search_github_repos.invoke({
            "keywords": keywords,
            "min_stars": settings.LIMITS["github_min_stars"]
        })
        logger.info(f"   âœ… {len(github_repos)}ê°œ ì €ì¥ì†Œ ìˆ˜ì§‘ ì™„ë£Œ\n")
    except Exception as e:
        error_msg = f"GitHub ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
        logger.error(f"   âŒ {error_msg}\n")
        error_log.append(error_msg)
    
    # 3. Google Trends ìˆ˜ì§‘
    google_trends = {}
    try:
        logger.info("3ï¸âƒ£ Google Trends ê²€ìƒ‰ ì¤‘...")
        timeframe = f"{settings.ANALYSIS['date_range']['start']} {settings.ANALYSIS['date_range']['end']}"
        google_trends = search_google_trends.invoke({
            "keywords": keywords,
            "timeframe": timeframe
        })
        logger.info(f"   âœ… {len(google_trends)}ê°œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì™„ë£Œ\n")
    except Exception as e:
        error_msg = f"Google Trends ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
        logger.error(f"   âŒ {error_msg}\n")
        error_log.append(error_msg)
    
    # 4. ê²°ê³¼ ìš”ì•½
    logger.info("="*70)
    logger.info("âœ… Agent 1: ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    logger.info("="*70)
    logger.info(f"   ğŸ“„ ë…¼ë¬¸: {len(papers)}ê°œ")
    logger.info(f"   ğŸ™ GitHub: {len(github_repos)}ê°œ")
    logger.info(f"   ğŸ“Š Trends: {len(google_trends)}ê°œ í‚¤ì›Œë“œ")
    logger.info("="*70 + "\n")
    
    return {
        "papers": papers,
        "github_repos": github_repos,
        "google_trends": google_trends,
        "error_log": error_log,
        "messages": [{
            "role": "assistant",
            "content": f"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: ë…¼ë¬¸ {len(papers)}ê°œ, GitHub {len(github_repos)}ê°œ"
        }],
        "current_step": "data_collected"
    }