# scripts/test_report.py
"""
ë¦¬í¬íŠ¸ ìƒì„± ë…¸ë“œë§Œ í…ŒìŠ¤íŠ¸ (PDFë§Œ ìƒì„±)
"""
import sys
import os
import warnings

# âœ… ëª¨ë“  ê²½ê³  ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")
os.environ['PYTHONWARNINGS'] = 'ignore'

# âœ… GLib ê²½ê³  ì™„ì „íˆ ìˆ¨ê¸°ê¸° (Windows)
if os.name == 'nt':
    import io
    sys.stderr = io.StringIO()  # stderrë¥¼ ë©”ëª¨ë¦¬ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python Pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from nodes.report_node import report_generation_node
from config.settings import settings
from utils.logger import logger
from datetime import datetime

def create_mock_state():
    """í…ŒìŠ¤íŠ¸ìš© Mock State ìƒì„±"""
    
    top_5_trends = [
        {
            "rank": 1,
            "trend_keyword": "large language model Ã— ì˜ë£Œ ì§„ë‹¨ ë³´ì¡°",
            "final_score": 55.3,
            "tech": {
                "tech_name": "large language model",
                "maturity_score": 100.0,
                "paper_count": 100,
                "github_stars_total": 342435,
                "related_projects": ["NVIDIA-NeMo", "IBM/ibm-generative-ai", "lm-sys/FastChat"]
            },
            "market": {
                "demand_name": "ì˜ë£Œ ì§„ë‹¨ ë³´ì¡°",
                "problem_statement": "ì˜ë£Œ ì˜ìƒ íŒë… ë° ì§„ë‹¨ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ê²ƒ",
                "opportunity_score": 88.0,
                "tam_usd": 700000000,
                "cagr": 0.52,
                "target_companies": 100000,
                "industries": ["healthcare"],
                "regions": ["ê¸€ë¡œë²Œ"]
            },
            "competition": 90.0,
            "rag_insight": {
                "answer": "OECD ë³´ê³ ì„œì— ë”°ë¥´ë©´ AI ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ì‹œìŠ¤í…œì€ 2030ë…„ê¹Œì§€ ê¸€ë¡œë²Œ í—¬ìŠ¤ì¼€ì–´ ì‹œì¥ì˜ í•µì‹¬ ê¸°ìˆ ë¡œ ìë¦¬ì¡ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."
            }
        },
        {
            "rank": 2,
            "trend_keyword": "large language model Ã— ì½˜í…ì¸  í¬ë¦¬ì—ì´í„° ì§€ì›",
            "final_score": 51.8,
            "tech": {
                "tech_name": "large language model",
                "maturity_score": 100.0,
                "paper_count": 100,
                "github_stars_total": 342435,
                "related_projects": ["OpenAI/gpt-4", "anthropic/claude"]
            },
            "market": {
                "demand_name": "ì½˜í…ì¸  í¬ë¦¬ì—ì´í„° ì§€ì›",
                "problem_statement": "ì½˜í…ì¸  ì œì‘ ë¹„ìš©ê³¼ ì‹œê°„ ë¶€ë‹´",
                "opportunity_score": 76.0,
                "tam_usd": 400000000,
                "cagr": 0.55,
                "target_companies": 2000000,
                "industries": ["media", "entertainment", "marketing"],
                "regions": ["ê¸€ë¡œë²Œ"]
            },
            "competition": 90.0,
            "rag_insight": {
                "answer": "í¬ë¦¬ì—ì´í„° ì´ì½”ë…¸ë¯¸ëŠ” 2030ë…„ê¹Œì§€ ì—°í‰ê·  55% ì„±ì¥í•  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤."
            }
        },
        {
            "rank": 3,
            "trend_keyword": "generative AI Ã— ì˜ë£Œ ì§„ë‹¨ ë³´ì¡°",
            "final_score": 51.2,
            "tech": {
                "tech_name": "generative AI",
                "maturity_score": 80.7,
                "paper_count": 80,
                "github_stars_total": 61314,
                "related_projects": ["NVIDIA-NeMo", "andrewyng/aisuite"]
            },
            "market": {
                "demand_name": "ì˜ë£Œ ì§„ë‹¨ ë³´ì¡°",
                "problem_statement": "ì˜ë£Œ ì˜ìƒ íŒë… ë° ì§„ë‹¨ì˜ ì •í™•ì„± í–¥ìƒ",
                "opportunity_score": 88.0,
                "tam_usd": 700000000,
                "cagr": 0.52,
                "target_companies": 100000,
                "industries": ["healthcare"],
                "regions": ["ê¸€ë¡œë²Œ"]
            },
            "competition": 85.0,
            "rag_insight": {
                "answer": "ìƒì„±í˜• AIëŠ” ì˜ë£Œ ì˜ìƒ ë¶„ì„ì—ì„œ 90% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            }
        },
        {
            "rank": 4,
            "trend_keyword": "large language model Ã— ì¤‘ì†Œê¸°ì—… ì—…ë¬´ ìë™í™”",
            "final_score": 51.1,
            "tech": {
                "tech_name": "large language model",
                "maturity_score": 100.0,
                "paper_count": 100,
                "github_stars_total": 342435,
                "related_projects": ["OpenAI/chatgpt", "Microsoft/copilot"]
            },
            "market": {
                "demand_name": "ì¤‘ì†Œê¸°ì—… ì—…ë¬´ ìë™í™”",
                "problem_statement": "ì¸ê±´ë¹„ ìƒìŠ¹ ë° ì±„ìš©ë‚œ ì‹¬í™”",
                "opportunity_score": 78.8,
                "tam_usd": 500000000,
                "cagr": 0.48,
                "target_companies": 500000,
                "industries": ["ì œì¡°", "ì†Œë§¤", "ì„œë¹„ìŠ¤"],
                "regions": ["í•œêµ­", "ë™ë‚¨ì•„ì‹œì•„"]
            },
            "competition": 90.0,
            "rag_insight": {
                "answer": "ì¤‘ì†Œê¸°ì—…ì˜ AI ë„ì…ë¥ ì€ 2025ë…„ 20%ì—ì„œ 2030ë…„ 60%ë¡œ ì¦ê°€í•  ì „ë§ì…ë‹ˆë‹¤."
            }
        },
        {
            "rank": 5,
            "trend_keyword": "edge AI Ã— ì˜ë£Œ ì§„ë‹¨ ë³´ì¡°",
            "final_score": 50.8,
            "tech": {
                "tech_name": "edge AI",
                "maturity_score": 52.1,
                "paper_count": 100,
                "github_stars_total": 4227,
                "related_projects": ["sipeed/MaixPy-v1", "kaixxx/noScribe"]
            },
            "market": {
                "demand_name": "ì˜ë£Œ ì§„ë‹¨ ë³´ì¡°",
                "problem_statement": "ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ë° ê°œì¸ì •ë³´ ë³´í˜¸",
                "opportunity_score": 88.0,
                "tam_usd": 700000000,
                "cagr": 0.52,
                "target_companies": 100000,
                "industries": ["healthcare"],
                "regions": ["ê¸€ë¡œë²Œ"]
            },
            "competition": 40.0,
            "rag_insight": {
                "answer": "Edge AIëŠ” ì˜ë£Œ ê¸°ê¸°ì—ì„œ ì‹¤ì‹œê°„ ì§„ë‹¨ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì‘ê¸‰ ìƒí™© ëŒ€ì‘ ì‹œê°„ì„ 50% ë‹¨ì¶•í•©ë‹ˆë‹¤."
            }
        }
    ]
    
    papers = [
        {
            "id": "2510.18876",
            "title": "Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs",
            "authors": ["Haochen Wang"],
            "abstract": "Recent advances...",
            "publish_date": "2025-10-21",
            "keywords": ["multimodal AI"],
            "url": "http://arxiv.org/abs/2510.18876v1"
        }
    ]
    
    github_repos = [
        {
            "full_name": "IBM/ibm-generative-ai",
            "html_url": "https://github.com/IBM/ibm-generative-ai",
            "stars": 21000,
            "description": "IBM Generative AI SDK"
        }
    ]
    
    keywords = ["generative AI", "large language model", "LLM agent", "multimodal AI", "edge AI", "AI automation"]
    
    return {
        "user_query": "2025-2030 AI íŠ¸ë Œë“œ ë¶„ì„",
        "keywords": keywords,
        "messages": [],
        "papers": papers,
        "github_repos": github_repos,
        "google_trends": {},
        "tech_trends": [],
        "market_demands": [],
        "rag_analysis": {},
        "trend_matrix": [],
        "top_5_trends": top_5_trends,
        "final_report": "",
        "error_log": [],
        "step_collector": "completed",
        "step_tech": "completed",
        "step_market": "completed",
        "step_rag": "completed",
        "step_cross": "completed",
        "step_report": None
    }


def main():
    """ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    # âœ… stderr ë³µì› (logger ì¶œë ¥ì„ ìœ„í•´)
    sys.stderr = sys.__stderr__
    
    logger.info("="*70)
    logger.info("ğŸ§ª ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ (PDFë§Œ)")
    logger.info("="*70)
    
    logger.info("\n1ï¸âƒ£ Mock State ìƒì„± ì¤‘...")
    mock_state = create_mock_state()
    logger.info(f"   âœ“ Top 5 íŠ¸ë Œë“œ: {len(mock_state['top_5_trends'])}ê°œ")
    
    logger.info("\n2ï¸âƒ£ PDF ìƒì„± ì‹¤í–‰...")
    start_time = datetime.now()
    
    try:
        result = report_generation_node(mock_state)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("\n" + "="*70)
        logger.info("âœ… ì™„ë£Œ!")
        logger.info("="*70)
        logger.info(f"\nâ±ï¸  ì‹¤í–‰ ì‹œê°„: {duration:.1f}ì´ˆ ({duration/60:.1f}ë¶„)")
        
        # PDF íŒŒì¼ í™•ì¸
        import glob
        pdf_files = glob.glob("outputs/reports/AI_TRENDS_*.pdf")
        
        if pdf_files:
            latest_pdf = max(pdf_files, key=os.path.getctime)
            logger.info(f"\nğŸ“„ ìƒì„±ëœ PDF:")
            logger.info(f"   {latest_pdf}")
            logger.info(f"   í¬ê¸°: {os.path.getsize(latest_pdf) / 1024 / 1024:.1f} MB\n")
        
        return True
        
    except Exception as e:
        logger.error(f"\nâŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)